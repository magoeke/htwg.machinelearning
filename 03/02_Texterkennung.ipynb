{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ãœbung 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Textklassifikation mit multinomialen Bayesklassifikator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a) Herunterladen und Entpacken der Datenbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import tarfile\n",
    "import os.path\n",
    "import urllib.request\n",
    "import skimage\n",
    "import scipy as sp\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = \"20news-18828.tar.gz\"\n",
    "url = \"http://qwone.com/~jason/20Newsgroups/\" + filename\n",
    "if not os.path.isfile(\"./\" + filename):\n",
    "    urllib.request.urlretrieve(url, filename)\n",
    "    dateDownloaded = !date\n",
    "    print(dateDownloaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tar = tarfile.open(\"./\" + filename)\n",
    "tar.extractall()\n",
    "tar.close()\n",
    "foldername = filename.replace(\".tar.gz\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3387"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import codecs\n",
    "newsgroup_names = [\"alt.atheism\", \"comp.graphics\", \"sci.space\", \"talk.religion.misc\"]\n",
    "newsgroups = {}\n",
    "for newsgroup_name in newsgroup_names:\n",
    "    newsgroup_folder = foldername+\"/\"+newsgroup_name\n",
    "    text_names = os.listdir(newsgroup_folder)\n",
    "    for text_name in text_names:\n",
    "        with open(newsgroup_folder+\"/\"+text_name, \"r\",encoding='ISO-8859-1') as f:\n",
    "            text = f.read()\n",
    "            newsgroups.update({text_name : [newsgroup_name, text]})\n",
    "newsgroups\n",
    "len(newsgroups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3387"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for newsgroup_key in newsgroups:\n",
    "    not_used, not_used, stripped_text = newsgroups[newsgroup_key][1].partition('\\n\\n')\n",
    "    newsgroups.update({newsgroup_key : [newsgroups[newsgroup_key][0],stripped_text]})\n",
    "newsgroups\n",
    "len(newsgroups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "word_count_newsgroups = {}\n",
    "for newsgroup_key in newsgroups:\n",
    "    splitted_text = re.compile(r\"(?u)\\b\\w\\w+\\b\").findall(newsgroups[newsgroup_key][1].lower())\n",
    "    word_count = {i:splitted_text.count(i) for i in splitted_text}\n",
    "    word_count_newsgroups.update({newsgroup_key : word_count})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41777"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_all = {}\n",
    "for word_count_newsgroups_key in word_count_newsgroups:\n",
    "    for single_word_count_key in newsgroups_splitted[word_count_newsgroups_key]:\n",
    "        #print(single_word_count_key, newsgroups_splitted[word_count_newsgroups_key][single_word_count_key] )\n",
    "        if single_word_count_key not in word_count_all:\n",
    "            word_count_all.update({single_word_count_key : newsgroups_splitted[word_count_newsgroups_key][single_word_count_key]})\n",
    "        else:\n",
    "            multiple_word_count = newsgroups_splitted[word_count_newsgroups_key][single_word_count_key] + word_count_all[single_word_count_key]\n",
    "            word_count_all.update({single_word_count_key : multiple_word_count})\n",
    "len(word_count_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert_words(word_count_classes, class_key, word_count):\n",
    "    if class_key not in word_count_classes:\n",
    "        word_count_classes.update({class_key : word_count})\n",
    "    else:\n",
    "        for word in word_count:\n",
    "            if word not in word_count_classes[class_key]:\n",
    "                word_count_classes[class_key].update({word : word_count[word]})\n",
    "            else:\n",
    "                mulitple_word_count = word_count_classes[class_key][word] + word_count[word]\n",
    "                word_count_classes[class_key].update({word : multiple_word_count})\n",
    "    return word_count_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sci.space 15350\n",
      "talk.religion.misc 11925\n",
      "alt.atheism 11784\n",
      "comp.graphics 13896\n",
      "sci.space 12129\n",
      "talk.religion.misc 9269\n",
      "alt.atheism 10028\n",
      "comp.graphics 11295\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "newsgroups_keys_shuffled = list(newsgroups.keys())\n",
    "shuffle(newsgroups_keys_shuffled)\n",
    "split_size = int(len(newsgroups_keys_shuffled)*0.6)\n",
    "word_count_classes_training = {}\n",
    "word_count_classes_test = {}\n",
    "word_count_text_training = {}\n",
    "word_count_text_test = {}\n",
    "for newsgroup_key, index in zip(newsgroups_keys_shuffled,range(0,len(newsgroups_keys_shuffled))):\n",
    "    splitted_text = re.compile(r\"(?u)\\b\\w\\w+\\b\").findall(newsgroups[newsgroup_key][1].lower())\n",
    "    word_count = {i:splitted_text.count(i) for i in splitted_text}\n",
    "    class_key = newsgroups[newsgroup_key][0]\n",
    "    if index < split_size:                            \n",
    "        word_count_classes_training=insert_words(word_count_classes_training, class_key, word_count)\n",
    "        word_count_text_training = insert_words(word_count_text_training, newsgroup_key, word_count)\n",
    "    else:\n",
    "        word_count_classes_test=insert_words(word_count_classes_test, class_key, word_count)\n",
    "        word_count_text_test = insert_words(word_count_text_test, newsgroup_key, word_count)\n",
    "                \n",
    "for class_key in word_count_classes_training:\n",
    "    print(class_key, len(word_count_classes_training[class_key]))\n",
    "for class_key in word_count_classes_test:\n",
    "    print(class_key, len(word_count_classes_test[class_key]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#word_count_newsgroups words per text {newsgroup:{word:count}}\n",
    "#word_count_all all words over all texts {word:count}\n",
    "\n",
    "\n",
    "#word_count_classes_test words per class {class:{word:count}}\n",
    "#word_count_classes_training words per class {class:{word:count}}\n",
    "#word_count_text_test words per text {newsgroup:{words:count}}\n",
    "#word_count_text_training words per text {newsgroup:{words:count}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A-Priori Wahrscheinlichkeit dass es sich um eine bestimmte Klasse handelt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alt.atheism': 0.22252856198659238,\n",
       " 'comp.graphics': 0.26241148144651116,\n",
       " 'sci.space': 0.28986875649136057,\n",
       " 'talk.religion.misc': 0.22519120007553584}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apriori_classes = {}\n",
    "total_words_in_class = 0\n",
    "\n",
    "for class_key in word_count_classes_training:\n",
    "    total_words_in_class += len(word_count_classes_training[class_key])\n",
    "\n",
    "for class_key in word_count_classes_training:\n",
    "    apriori_classes[class_key] = len(word_count_classes_training[class_key]) / total_words_in_class\n",
    "    \n",
    "apriori_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainings_matrix = {}\n",
    "for class_key, word_dict in word_count_classes_training.items():\n",
    "    number_words_in_class = len(word_dict)\n",
    "    trainings_matrix[class_key] = {}\n",
    "    for word in word_count_all:\n",
    "        word_frequency = 0\n",
    "        if word in word_dict:\n",
    "            word_frequency = word_dict[word]\n",
    "        probability = (word_frequency + 1) / (len(word_count_classes_training[class_key]) + len(word_count_all))\n",
    "        trainings_matrix[class_key][word] = probability\n",
    "        \n",
    "#trainings_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konfiguration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext version_information\n",
    "%version_information numpy, pandas, matplotlib, skimage"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
