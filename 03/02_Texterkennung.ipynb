{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ãœbung 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Textklassifikation mit multinomialen Bayesklassifikator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a) Herunterladen und Entpacken der Datenbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import tarfile\n",
    "import os.path\n",
    "import urllib.request\n",
    "import skimage\n",
    "import scipy as sp\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = \"20news-18828.tar.gz\"\n",
    "url = \"http://qwone.com/~jason/20Newsgroups/\" + filename\n",
    "if not os.path.isfile(\"./\" + filename):\n",
    "    urllib.request.urlretrieve(url, filename)\n",
    "    dateDownloaded = !date\n",
    "    print(dateDownloaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tar = tarfile.open(\"./\" + filename)\n",
    "tar.extractall()\n",
    "tar.close()\n",
    "foldername = filename.replace(\".tar.gz\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3387"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import codecs\n",
    "newsgroup_names = [\"alt.atheism\", \"comp.graphics\", \"sci.space\", \"talk.religion.misc\"]\n",
    "newsgroups = {}\n",
    "for newsgroup_name in newsgroup_names:\n",
    "    newsgroup_folder = foldername+\"/\"+newsgroup_name\n",
    "    text_names = os.listdir(newsgroup_folder)\n",
    "    for text_name in text_names:\n",
    "        with open(newsgroup_folder+\"/\"+text_name, \"r\",encoding='ISO-8859-1') as f:\n",
    "            text = f.read()\n",
    "            newsgroups.update({text_name : [newsgroup_name, text]})\n",
    "newsgroups\n",
    "len(newsgroups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3387"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for newsgroup_key in newsgroups:\n",
    "    not_used, not_used, stripped_text = newsgroups[newsgroup_key][1].partition('\\n\\n')\n",
    "    newsgroups.update({newsgroup_key : [newsgroups[newsgroup_key][0],stripped_text]})\n",
    "newsgroups\n",
    "len(newsgroups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "word_count_newsgroups = {}\n",
    "for newsgroup_key in newsgroups:\n",
    "    splitted_text = re.compile(r\"(?u)\\b\\w\\w+\\b\").findall(newsgroups[newsgroup_key][1].lower())\n",
    "    word_count = {i:splitted_text.count(i) for i in splitted_text}\n",
    "    word_count_newsgroups.update({newsgroup_key : word_count})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41777"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_all = {}\n",
    "for word_count_newsgroups_key in word_count_newsgroups:\n",
    "    for single_word_count_key in newsgroups_splitted[word_count_newsgroups_key]:\n",
    "        #print(single_word_count_key, newsgroups_splitted[word_count_newsgroups_key][single_word_count_key] )\n",
    "        if single_word_count_key not in word_count_all:\n",
    "            word_count_all.update({single_word_count_key : newsgroups_splitted[word_count_newsgroups_key][single_word_count_key]})\n",
    "        else:\n",
    "            multiple_word_count = newsgroups_splitted[word_count_newsgroups_key][single_word_count_key] + word_count_all[single_word_count_key]\n",
    "            word_count_all.update({single_word_count_key : multiple_word_count})\n",
    "len(word_count_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#word_count_newsgroups words per text {newsgroup:{word:count}}\n",
    "#word_count_classes words per class {class:{word:count}}\n",
    "#word_count_all all words over all texts {word:count}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert_words(word_count_classes, class_key, word_count):\n",
    "    if class_key not in word_count_classes:\n",
    "        word_count_classes.update({class_key : word_count})\n",
    "    else:\n",
    "        for word in word_count:\n",
    "            if word not in word_count_classes[class_key]:\n",
    "                word_count_classes[class_key].update({word : word_count[word]})\n",
    "            else:\n",
    "                mulitple_word_count = word_count_classes[class_key][word] + word_count[word]\n",
    "                word_count_classes[class_key].update({word : multiple_word_count})\n",
    "    return word_count_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "newsgroups_keys_shuffled = list(newsgroups.keys())\n",
    "shuffle(newsgroups_keys_shuffled)\n",
    "word_count_classes_training = {}\n",
    "for newsgroup_key in newsgroups_keys_shuffled:\n",
    "    splitted_text = re.compile(r\"(?u)\\b\\w\\w+\\b\").findall(newsgroups[newsgroup_key][1].lower())\n",
    "    word_count = {i:splitted_text.count(i) for i in splitted_text}\n",
    "    class_key = newsgroups[newsgroup_key][0]\n",
    "    word_count_classes_training=insert_words(word_count_classes_training, class_key, word_count)\n",
    "                \n",
    "for class_key in word_count_classes_training:\n",
    "    print(class_key, len(word_count_classes_training[class_key]))\n",
    "    \n",
    "### TODO split in 60% training and 40% test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#training_data = []\n",
    "#training_data_newsgroup = []\n",
    "#test_data = []\n",
    "#test_data_newsgroup = []\n",
    "#split_size = int(len(word_count_newsgroups)*0.6)\n",
    "#\n",
    "#for word_count_newsgroups_key, index in zip(word_count_newsgroups,range(0,len(word_count_newsgroups))):\n",
    "#    word_count = np.empty([len( word_count_newsgroups[word_count_newsgroups_key]),2])\n",
    "#    for word, word_index in zip(word_count_newsgroups[word_count_newsgroups_key],range(0,len(word_count_newsgroups[word_count_newsgroups_key]))):\n",
    "#        word_count[word_index,0]=word\n",
    "#        word_count[word_index,1]=word_count_newsgroups[word_count_newsgroups_key][word]      \n",
    "#                                \n",
    "#    if index < split_size:\n",
    "#        training_data.append(word_cound)\n",
    "#        training_data_newsgroup.append(word_count_newsgroups_key)\n",
    "#    else:        \n",
    "#        test_data.append( word_count)\n",
    "#        test_data_newsgroup.append(word_count_newsgroups_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#training_data_mean = training_data.mean(axis=0)\n",
    "#centered_training_data = training_data.copy()\n",
    "#centered_training_data=centered_training_data-training_data_mean\n",
    "#\n",
    "#U, D, Vt = np.linalg.svd(training_data)\n",
    "#\n",
    "#eigenvalues = np.square(D)\n",
    "#\n",
    "#centered_test_data = test_data.copy()\n",
    "#centered_test_data=centered_test_data-training_data_mean\n",
    "#\n",
    "#eigen_values_dataframe = pd.DataFrame(eigenvalues[0:150])\n",
    "#\n",
    "#%pylab inline\n",
    "#eigen_values_dataframe.plot(logy=True)\n",
    "#\n",
    "#test_images = np.dot(Vt[:7], centered_test_data.T).T\n",
    "#training_images = np.dot(Vt[:7], centered_training_data.T).T\n",
    "#\n",
    "#test_images.shape, training_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konfiguration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext version_information\n",
    "%version_information numpy, pandas, matplotlib, skimage"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
