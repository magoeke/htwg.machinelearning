{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übung 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Gesichtserkennung mit Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import tarfile\n",
    "import os.path\n",
    "import urllib.request\n",
    "import skimage\n",
    "import scipy as sp\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"lfw-funneled.tgz\"\n",
    "url = \"http://vis-www.cs.umass.edu/lfw/\" + filename\n",
    "if not os.path.isfile(\"../02/\" + filename):\n",
    "    urllib.request.urlretrieve(url, filename)\n",
    "    dateDownloaded = !date\n",
    "    print(dateDownloaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tar = tarfile.open(\"../02/\" + filename)\n",
    "tar.extractall()\n",
    "tar.close()\n",
    "foldername = \"lfw_funneled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Colin_Powell', 'George_W_Bush', 'Tony_Blair', 'Gerhard_Schroeder', 'Ariel_Sharon', 'Hugo_Chavez', 'Donald_Rumsfeld'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persons = {}\n",
    "for personName in os.listdir(foldername):\n",
    "    current_person = foldername + \"/\" + personName\n",
    "    if os.path.isdir(current_person):\n",
    "        if len(os.listdir(current_person)) >= 70:\n",
    "            shuffled_dir_list = os.listdir(current_person)\n",
    "            shuffle(shuffled_dir_list)\n",
    "            persons.update({personName: [current_person +\"/\"+item for item in shuffled_dir_list] })\n",
    "persons.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((770, 204), (770,), (518, 204), (518,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skimage import io\n",
    "from skimage import transform\n",
    "\n",
    "resized_images = []\n",
    "resized_names = []\n",
    "resized_last_images = []\n",
    "resized_last_names = []\n",
    "\n",
    "for person_name, person in zip(persons.keys(), persons.values()):\n",
    "    path = person.copy()\n",
    "    size = (int)(len(path) * 0.6)\n",
    "    for picture_path in path:\n",
    "        picture = io.imread(picture_path,  as_grey=True)\n",
    "        picture = picture[55:195, 75:175]\n",
    "        resized_image = transform.resize(picture, ((int)(picture.shape[0]/8), (int)(picture.shape[1]/8))).flatten()\n",
    "        if picture_path not in path[size:len(path)]:\n",
    "            resized_images.append(resized_image)\n",
    "            resized_names.append(person_name)\n",
    "        else:\n",
    "            resized_last_images.append(resized_image)\n",
    "            resized_last_names.append(person_name)\n",
    "\n",
    "resized_images = np.array(resized_images)\n",
    "resized_names = np.array(resized_names)\n",
    "resized_last_images = np.array(resized_last_images)\n",
    "resized_last_names = np.array(resized_last_names)\n",
    "        \n",
    "resized_images.shape, resized_names.shape, resized_last_images.shape, resized_last_names.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Führen Sie anschließend eine Hauptkomponentenanalyse auf den Trainingsdaten durch und projizieren Sie sowohl Trainings- als auch Testbilder auf die ersten 7 Eigengesichter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((518, 7), (770, 7))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_mean = resized_images.mean(axis=0)\n",
    "centered_training_data = resized_images.copy()\n",
    "centered_training_data=centered_training_data-training_data_mean\n",
    "\n",
    "U, D, Vt = np.linalg.svd(resized_images)\n",
    "\n",
    "eigenvalues = np.square(D)\n",
    "\n",
    "centered_test_data = resized_last_images.copy()\n",
    "centered_test_data=centered_test_data-training_data_mean\n",
    "\n",
    "test_images = np.dot(Vt[:7], centered_test_data.T).T\n",
    "training_images = np.dot(Vt[:7], centered_training_data.T).T\n",
    "\n",
    "test_images.shape, training_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainieren Sie Ihren GNB-Klassifikator auf dem Trainingsdatensatz als “George-W.-Bush-Detektor”, d.h. alle zu dieser Person gehörigen Bilder werden mit 1 gelabelt, alle sonstigen mit –1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318, 452, 212, 306)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_names = resized_names\n",
    "training_labels = []\n",
    "for training_image, training_name in zip(training_images, training_names):\n",
    "    if training_name == \"George_W_Bush\":\n",
    "        training_labels.append(1)\n",
    "    else:\n",
    "         training_labels.append(-1) \n",
    "            \n",
    "test_names = resized_last_names  \n",
    "test_labels = []\n",
    "for test_image, test_name in zip(test_images, test_names):\n",
    "    if test_name == \"George_W_Bush\":\n",
    "        test_labels.append(1)\n",
    "    else:\n",
    "         test_labels.append(-1) \n",
    "\n",
    "training_labels.count(1), training_labels.count(-1), test_labels.count(1), test_labels.count(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_not_bush = np.empty((0,training_images.shape[1]))\n",
    "training_bush =  np.empty((0,training_images.shape[1]))\n",
    "for training_name, training_label, training_image in zip(training_names, training_labels, training_images):\n",
    "    if training_label == 1:\n",
    "        training_bush = np.vstack((training_bush, training_image))\n",
    "    else:\n",
    "        training_not_bush = np.vstack((training_not_bush, training_image))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folie 18: Mittelwert und Standardabweichung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.0090049 , -0.06523724, -0.02842088, -0.01806657,  0.01931427,\n",
       "         0.07233456,  0.07038197]),\n",
       " array([-0.01279942,  0.09272714,  0.04039697,  0.02567953, -0.02745299,\n",
       "        -0.10281516, -0.10003978]),\n",
       " array([-0.00524298,  0.02155068, -0.0147656 ,  0.07582233, -0.04397217,\n",
       "        -0.01345407, -0.00579986]),\n",
       " array([ 0.92356836,  0.75537408,  0.75506869,  0.5730736 ,  0.48295888,\n",
       "         0.4253986 ,  0.37911711]),\n",
       " array([ 0.89228356,  0.83462759,  0.56375236,  0.56776292,  0.50128039,\n",
       "         0.33123315,  0.32451962]),\n",
       " array([ 0.97310811,  0.82192401,  0.67646418,  0.6116846 ,  0.45920356,\n",
       "         0.38701692,  0.35101323]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_not_bush_mean = np.mean(training_not_bush, axis=0)\n",
    "training_bush_mean =np.mean(training_bush, axis=0)\n",
    "test_images_mean = np.mean(test_images, axis=0)\n",
    "\n",
    "training_not_bush_std = np.std(training_not_bush, axis=0)\n",
    "training_bush_std =np.std(training_bush, axis=0)\n",
    "test_images_std = np.std(test_images, axis=0)\n",
    "\n",
    "training_not_bush_mean, training_bush_mean, test_images_mean, training_not_bush_std, training_bush_std, test_images_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A-Priori Wahrscheinlichkeiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.412987012987013, 0.587012987012987)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apriori_bush = training_bush.shape[0] / (training_bush.shape[0]+training_not_bush.shape[0])\n",
    "apriori_not_bush = training_not_bush.shape[0] / (training_bush.shape[0]+training_not_bush.shape[0])\n",
    "apriori_bush, apriori_not_bush"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gaussian_distribution_bush = sp.stats.norm(training_bush_mean, training_bush_std).pdf(test_images)\n",
    "gaussian_distribution_not_bush = sp.stats.norm(training_not_bush_mean, training_not_bush_std).pdf(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wahrscheinlichkeit, dass Testbild Bush ist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((518,), (518,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_bush = np.prod(gaussian_distribution_bush, axis=1) * apriori_bush\n",
    "probability_not_bush = np.prod(gaussian_distribution_not_bush, axis=1) * apriori_not_bush\n",
    "probability_bush.shape, probability_not_bush.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Werten Sie Ihren Klassifikator sowohl auf den Trainings- wie auf den unabhängigen Testdaten aus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bestimmen Sie dafür jeweils die Detektionswahrscheinlichkeit, Richtig-Negativ-Rate, Fehlalarmrate und Falsch-Negativ-Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wahrscheinlichkeit für richtige Klassifikation:  67.56756756756756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(142, 208, 98, 70)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positive = 0\n",
    "false_negative = 0\n",
    "true_positive = 0\n",
    "true_negative = 0\n",
    "\n",
    "i = 0\n",
    "\n",
    "classifications = (probability_bush / probability_not_bush)-1\n",
    "for result in classifications:\n",
    "    if result < 0:\n",
    "        if test_labels[i] == -1:\n",
    "            true_negative +=1\n",
    "        else:\n",
    "            false_negative +=1\n",
    "    elif result > 0:\n",
    "        if test_labels[i] == 1:\n",
    "            true_positive +=1\n",
    "        else:\n",
    "            false_positive +=1\n",
    "    elif result == 0:\n",
    "        pass\n",
    "    i+=1\n",
    "\n",
    "print(\"Wahrscheinlichkeit für richtige Klassifikation: \", (true_positive + true_negative)/probability_bush.shape[0]*100)\n",
    "true_positive, true_negative, false_positive, false_negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konfiguration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The version_information extension is already loaded. To reload it, use:\n",
      "  %reload_ext version_information\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "Software versions": [
        {
         "module": "Python",
         "version": "3.5.2 64bit [GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]"
        },
        {
         "module": "IPython",
         "version": "5.1.0"
        },
        {
         "module": "OS",
         "version": "Linux 4.2.0 27 generic x86_64 with debian jessie sid"
        },
        {
         "module": "numpy",
         "version": "1.11.1"
        },
        {
         "module": "pandas",
         "version": "0.18.1"
        },
        {
         "module": "matplotlib",
         "version": "1.5.3"
        },
        {
         "module": "skimage",
         "version": "0.12.3"
        }
       ]
      },
      "text/html": [
       "<table><tr><th>Software</th><th>Version</th></tr><tr><td>Python</td><td>3.5.2 64bit [GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]</td></tr><tr><td>IPython</td><td>5.1.0</td></tr><tr><td>OS</td><td>Linux 4.2.0 27 generic x86_64 with debian jessie sid</td></tr><tr><td>numpy</td><td>1.11.1</td></tr><tr><td>pandas</td><td>0.18.1</td></tr><tr><td>matplotlib</td><td>1.5.3</td></tr><tr><td>skimage</td><td>0.12.3</td></tr><tr><td colspan='2'>Mon Dec 19 09:28:48 2016 CET</td></tr></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{|l|l|}\\hline\n",
       "{\\bf Software} & {\\bf Version} \\\\ \\hline\\hline\n",
       "Python & 3.5.2 64bit [GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] \\\\ \\hline\n",
       "IPython & 5.1.0 \\\\ \\hline\n",
       "OS & Linux 4.2.0 27 generic x86\\_64 with debian jessie sid \\\\ \\hline\n",
       "numpy & 1.11.1 \\\\ \\hline\n",
       "pandas & 0.18.1 \\\\ \\hline\n",
       "matplotlib & 1.5.3 \\\\ \\hline\n",
       "skimage & 0.12.3 \\\\ \\hline\n",
       "\\hline \\multicolumn{2}{|l|}{Mon Dec 19 09:28:48 2016 CET} \\\\ \\hline\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "Software versions\n",
       "Python 3.5.2 64bit [GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n",
       "IPython 5.1.0\n",
       "OS Linux 4.2.0 27 generic x86_64 with debian jessie sid\n",
       "numpy 1.11.1\n",
       "pandas 0.18.1\n",
       "matplotlib 1.5.3\n",
       "skimage 0.12.3\n",
       "Mon Dec 19 09:28:48 2016 CET"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext version_information\n",
    "%version_information numpy, pandas, matplotlib, skimage"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
