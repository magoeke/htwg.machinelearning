{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ãœbung 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Klassifikation mit SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import skimage\n",
    "import scipy as sp\n",
    "from sklearn import datasets, svm, model_selection\n",
    "#from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a) Laden der Daten und Beschreibung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Optical Recognition of Handwritten Digits Data Set\\n===================================================\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 5620\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttp://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\nReferences\\n----------\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.DESCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Merkmalsvektoren (hier Bilder) sind die Zeilen der Designmatrix digits.data. Zusammenstellung einer Zufallsauswahl von 10 Bildern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAABTCAYAAACGep5WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIvx/5wUvtUM0YjAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe7ac3bfb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "%matplotlib inline\n",
    "fig = mp.pyplot.figure()\n",
    "indexes = random.sample(range(0, len(digits.target)), 10)\n",
    "images = []\n",
    "for i, index in zip(range(1, 11), indexes):\n",
    "    mp.pyplot.subplot(1, 10, i)\n",
    "    mp.pyplot.imshow(digits.images[index], cmap=mp.pyplot.cm.gray_r, interpolation='nearest')\n",
    "    images.append((digits.target[index],digits.data[index])) #(label, image)\n",
    "\n",
    "mp.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anzahl Bilder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimension der Bilder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8, 8), (64,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.images[0].shape, digits.data[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teilen Sie den Datensatz zufÃ¤llig in einen nichtÃ¼berlappenden Trainings- und Testdatensatz auf, so dass ein Viertel der Daten zu Testdaten werden. Dies geschieht am Einfachsten mit der Funktion sklearn.model_selection.train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((450, 64), (450,), (1347, 64), (1347,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data, test_data, training_label, test_label = model_selection.train_test_split(digits.data, digits.target, test_size=0.25)\n",
    "test_data.shape, test_label.shape, training_data.shape, training_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainieren Sie einen Supportvektor-Klassifikator (Standard in Scikit Learn ist eine 1-Norm Soft Margin SVM, bei Mehrklassenproblemen wird automatisch ein Satz von one-vs.-one-Klassifikatoren erstellt) mit einem RBF-Kern mit Î³ = 0.015 und einem Parameter C = 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.015, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(gamma=0.015, C=1.0)\n",
    "clf.fit(training_data, training_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bestimmen Sie den Anteil korrekt klassifizierter Beispiele (Korrektklassifikationsrate, Treffergenauigkeit, engl. Accuracy) im Trainings- und Testdatensatz mithilfe der Funktion SVC.score(). Underfitting liegt vor, wenn Ihr Klassifikator auf den Trainingsdatensatz eine Treffergenauigkeit von deutlich unter 100% erzielt, bei Overfitting liegt die Treffergenauigkeit auf dem Testdatensatz deutlich unter der auf dem Trainingsdatensatz. Welcher Fall liegt hier vor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.366666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected = test_label\n",
    "predicted = clf.predict(test_data)\n",
    "\n",
    "print(clf.score(test_data, test_label))\n",
    "clf.score(training_data, training_label)\n",
    "#expected, predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es handelt sich hierbei um Overfitting. 1.0 > 0.33"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probieren Sie alternativ die SVM-Parameter Î³ = 0.001 und C = 100 und vergleichen Sie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.991111111111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(gamma=0.001, C=100)\n",
    "clf.fit(training_data, training_label)\n",
    "\n",
    "print(clf.score(test_data, test_label))\n",
    "clf.score(training_data, training_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wiederholen\n",
    "Sie das Experiment fÃ¼r einen anderen Zufallssplit in Trainings- und Testdatensatz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.534269662921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_training_data, r_test_data, r_training_label, r_test_label = model_selection.train_test_split(digits.data, digits.target, test_size=0.99)\n",
    "\n",
    "clf = svm.SVC(gamma=0.001, C=100)\n",
    "clf.fit(r_training_data, r_training_label)\n",
    "\n",
    "print(clf.score(r_test_data, r_test_label))\n",
    "clf.score(r_training_data, r_training_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie stark hÃ¤ngt Ihr Ergebnis von der zufÃ¤lligen Teilung in Trainings- und Testdatensatz ab?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Es hÃ¤ngt sehr wenig davon ab, da schon wenige Trainingsdaten fÃ¼r ein gutes Ergebnis reichen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Kreuzvalidierung und Modellselektion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Bei der Methode der Kreuzvalidierung wird der zufÃ¤llige Split in Trainings- und Testdatensatz aus Aufgabe 1 mehrere Male wiederholt und der Durchschnitt Ã¼ber mehrere Splits berechnet, um eine genauere SchÃ¤tzung der wirklichen Treffergenauigkeit zu erhalten. Scikit Learn stellt dafÃ¼r bereits eine vordefinierte Methode zur VerfÃ¼gung: sklearn.model_selection.ShuffleSplit(). Die Methode verwendet die Iteratorsyntax von Python, Beispiele zur Verwendung finden Sie in der Dokumentation dieser Methode. ShuffleSplit() erzeugt einen Satz von permutierten Indizes von Trainings- und Testdaten. Erzeugen Sie zunÃ¤chst 3 SÃ¤tze und trainieren Sie fÃ¼r jeden Satz eine SVM mit Î³ = 0.001 und C = 1 und geben Sie jeweils die Treffergenauigkeit fÃ¼r Trainings- und Testdatensatz aus. Die Ergebnisse sollten Ã¤hnlich wie in Aufgabe 1b aussehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  0.995555555556\n",
      "Training  0.999257609503\n",
      "Test  0.995555555556\n",
      "Training  0.998515219005\n",
      "Test  0.993333333333\n",
      "Training  0.999257609503\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.99481481481481471, 0.99901014600346449)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_number = 3\n",
    "rs = model_selection.ShuffleSplit(n_splits=split_number, test_size=.25, random_state=0)\n",
    "\n",
    "training_mean = 0\n",
    "test_mean = 0\n",
    "\n",
    "for training_indexes, test_indexes in rs.split(digits.data):\n",
    "    t_test_data = []\n",
    "    t_test_label = []\n",
    "    t_training_data = []\n",
    "    t_training_label = []\n",
    "    for test_index in test_indexes:\n",
    "        t_test_data.append(digits.data[test_index])\n",
    "        t_test_label.append(digits.target[test_index])\n",
    "        \n",
    "    for training_index in training_indexes:\n",
    "        t_training_data.append(digits.data[training_index])\n",
    "        t_training_label.append(digits.target[training_index])\n",
    "        \n",
    "    clf = svm.SVC(gamma=0.001, C=1.0)\n",
    "    clf.fit(t_training_data, t_training_label)\n",
    "    test_score = clf.score(t_test_data, t_test_label)\n",
    "    training_score = clf.score(t_training_data, t_training_label)\n",
    "    \n",
    "    test_mean += test_score\n",
    "    training_mean += training_score\n",
    "    print(\"Test \", test_score)\n",
    "    print(\"Training \", training_score)\n",
    "    \n",
    "test_mean/split_number, training_mean/split_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Statt wie in 2a von Hand vorzugehen gibt es in Scikit Learn die bereits vordefinierte\n",
    "Methode sklearn.model_selection.cross_val_score(). Wiederholen Sie Ihr Experiment\n",
    "aus Aufgabe 2a mit 10 Zufallssplits und geben Sie jeweils die Treffergenauigkeit auf dem\n",
    "Testdatensatz aus. Berechnen Sie die mittlere Treffergenauigkeit (die Kreuzvalidierungs-\n",
    "genauigkeit) und die Standardabweichung des Mittelwerts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  [ 0.98039216  0.98        0.97278912]\n",
      "Training  [ 0.98893805  0.99109131  0.99103139]\n",
      "Test  [ 0.96753247  0.97986577  0.96598639]\n",
      "Training  [ 0.98675497  0.99111111  0.97972973]\n",
      "Test  [ 0.98013245  0.97350993  0.97972973]\n",
      "Training  [ 0.99115044  0.99109131  0.98430493]\n",
      "Test  [ 0.97368421  0.98666667  0.9527027 ]\n",
      "Training  [ 0.99115044  0.984375    0.99105145]\n",
      "Test  [ 0.96078431  0.94        0.96598639]\n",
      "Training  [ 0.98451327  0.98886414  0.97982063]\n",
      "Test  [ 0.98039216  0.97333333  0.97959184]\n",
      "Training  [ 0.99113082  0.99109131  0.97986577]\n",
      "Test  [ 0.97402597  0.94666667  0.97260274]\n",
      "Training  [ 0.99337748  0.98666667  0.99099099]\n",
      "Test  [ 0.99346405  0.93288591  0.95945946]\n",
      "Training  [ 0.98893805  0.98444444  0.97752809]\n",
      "Test  [ 0.98039216  0.96666667  0.97278912]\n",
      "Training  [ 0.98230088  0.98886414  0.99327354]\n",
      "Test  [ 0.97368421  0.98        0.95945946]\n",
      "Training  [ 0.99113082  0.9844098   0.98657718]\n"
     ]
    }
   ],
   "source": [
    "split_number = 10\n",
    "rs = model_selection.ShuffleSplit(n_splits=split_number, test_size=.25, random_state=0)\n",
    "\n",
    "training_mean = 0\n",
    "test_mean = 0\n",
    "\n",
    "for training_indexes, test_indexes in rs.split(digits.data):\n",
    "    t_test_data = []\n",
    "    t_test_label = []\n",
    "    t_training_data = []\n",
    "    t_training_label = []\n",
    "    for test_index in test_indexes:\n",
    "        t_test_data.append(digits.data[test_index])\n",
    "        t_test_label.append(digits.target[test_index])\n",
    "        \n",
    "    for training_index in training_indexes:\n",
    "        t_training_data.append(digits.data[training_index])\n",
    "        t_training_label.append(digits.target[training_index])\n",
    "        \n",
    "    clf = svm.SVC(gamma=0.001, C=1.0)\n",
    "    training_score = model_selection.cross_val_score(clf, t_training_data, t_training_label)\n",
    "    test_score = model_selection.cross_val_score(clf, t_test_data, t_test_label)\n",
    "    #clf.fit(t_training_data, t_training_label)\n",
    "    #test_score = clf.score(t_test_data, t_test_label)\n",
    "    #training_score = clf.score(t_training_data, t_training_label)\n",
    "    \n",
    "    #test_mean += test_score\n",
    "    #training_mean += training_score\n",
    "    print(\"Test \", test_score)\n",
    "    print(\"Training \", training_score)\n",
    "    \n",
    "#test_mean/split_number, training_mean/split_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Standardabweichung des Mittelwerts ist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mithilfe der Kreuzvalidierungsgenauigkeit kÃ¶nnen die optimalen Î³- und C-Parameter der SVM automatisch gefunden werden. Dieser Vorgang heiÃŸt Modellselektion. Man fÃ¼hrt zu diesem Zweck eine Gittersuche durch: zunÃ¤chst wird ein Satz von Werten fÃ¼r Î³ und C festgelegt. FÃ¼r alle Wertepaare wird die Kreuzvalidierungsgenauigkeit bestimmt und dann die Parameter gewÃ¤hlt, die die hÃ¶chste Treffergenauigkeit erzielen. Finden Sie auf diese Weise fÃ¼r C = 10 den besten Gammawert aus einem Satz von 10 logarithmisch skalierten Gammawerten, erzeugt mit\n",
    "\n",
    "    gammas = np . logspace ( -7 , -1 , 10)\n",
    "\n",
    "Verwenden Sie dazu eine Trainings- und TestdatensatzgrÃ¶ÃŸe von 500 und 5 Splits (s. Dokumentation von ShuffleSplit) und speichern Sie die Treffergenauigkeit auf dem Trainingsund Testdatensatz fÃ¼r jeden Gammawert und Split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotten Sie die Treffergenauigkeitskurve fÃ¼r jeden Split mit dem Gammawert als Abszisse in einem gemeinsamen Diagramm, jeweils fÃ¼r die Trainings- und die Testdaten. Diese Kurven werden Validierungskurven genannt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FÃ¼r welche Gammawerte erhalten Sie Underfitting, fÃ¼r welche Overfitting? Wo liegt der optimale Gammawert?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Gittersuche lÃ¤sst sich ebenfalls automatisieren mit sklearn.model_selection. GridSearchCV(). Wir erzeugen dazu ein Gitter aus Wertepaaren fÃ¼r Î³ und C mit dem Dictionary\n",
    "\n",
    "    svc_params = {\n",
    "        â€™C â€™: np . logspace ( -1 , 2 , 4) ,\n",
    "        â€™ gamma â€™: np . logspace ( -4 , 0 , 5) ,\n",
    "    }\n",
    "\n",
    "Dieses Gitter kann direkt an GridSearchCV() als Argument param_grid Ã¼bergeben werden. Da diese Prozedur sehr zeitaufwendig ist, verkleinern wie den Datensatz auf die ersten 500 Beispiele. FÃ¼hren Sie fÃ¼r diesen verkleinerten Datensatz eine Gittersuche mithilfe von GridSearchCV() und jeweils 3 Splits (Parameter cv) durch. Den besten Parametersatz erhalten Sie mit GridSearchCV().best_params_, die hÃ¶chste Treffergenauigkeit mit GridSearchCV().best_score_. AusfÃ¼hrliche Informationen zu jedem Parameterwertepaar stehen in dem Dictionary GridSearchCV().cv_results_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nach der Gittersuche fÃ¼hrt GridSearchCV() noch ein Training auf dem gesamten Datensatz mit den besten Parametern durch, so dass die resultierende Maschine sofort eingesetzt werden kann. Testen Sie diese Maschine auf den Ã¼briggebliebenen Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konfiguration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "Software versions": [
        {
         "module": "Python",
         "version": "3.5.2 64bit [GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]"
        },
        {
         "module": "IPython",
         "version": "5.1.0"
        },
        {
         "module": "OS",
         "version": "Linux 4.2.0 27 generic x86_64 with debian jessie sid"
        },
        {
         "module": "numpy",
         "version": "1.11.1"
        },
        {
         "module": "pandas",
         "version": "0.18.1"
        },
        {
         "module": "matplotlib",
         "version": "1.5.3"
        },
        {
         "module": "skimage",
         "version": "0.12.3"
        },
        {
         "module": "sklearn",
         "version": "0.18.1"
        }
       ]
      },
      "text/html": [
       "<table><tr><th>Software</th><th>Version</th></tr><tr><td>Python</td><td>3.5.2 64bit [GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]</td></tr><tr><td>IPython</td><td>5.1.0</td></tr><tr><td>OS</td><td>Linux 4.2.0 27 generic x86_64 with debian jessie sid</td></tr><tr><td>numpy</td><td>1.11.1</td></tr><tr><td>pandas</td><td>0.18.1</td></tr><tr><td>matplotlib</td><td>1.5.3</td></tr><tr><td>skimage</td><td>0.12.3</td></tr><tr><td>sklearn</td><td>0.18.1</td></tr><tr><td colspan='2'>Fri Dec 30 22:24:32 2016 CET</td></tr></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{|l|l|}\\hline\n",
       "{\\bf Software} & {\\bf Version} \\\\ \\hline\\hline\n",
       "Python & 3.5.2 64bit [GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] \\\\ \\hline\n",
       "IPython & 5.1.0 \\\\ \\hline\n",
       "OS & Linux 4.2.0 27 generic x86\\_64 with debian jessie sid \\\\ \\hline\n",
       "numpy & 1.11.1 \\\\ \\hline\n",
       "pandas & 0.18.1 \\\\ \\hline\n",
       "matplotlib & 1.5.3 \\\\ \\hline\n",
       "skimage & 0.12.3 \\\\ \\hline\n",
       "sklearn & 0.18.1 \\\\ \\hline\n",
       "\\hline \\multicolumn{2}{|l|}{Fri Dec 30 22:24:32 2016 CET} \\\\ \\hline\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "Software versions\n",
       "Python 3.5.2 64bit [GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n",
       "IPython 5.1.0\n",
       "OS Linux 4.2.0 27 generic x86_64 with debian jessie sid\n",
       "numpy 1.11.1\n",
       "pandas 0.18.1\n",
       "matplotlib 1.5.3\n",
       "skimage 0.12.3\n",
       "sklearn 0.18.1\n",
       "Fri Dec 30 22:24:32 2016 CET"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext version_information\n",
    "%version_information numpy, pandas, matplotlib, skimage, sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
