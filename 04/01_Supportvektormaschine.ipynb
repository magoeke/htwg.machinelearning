{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übung 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Klassifikation mit SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import skimage\n",
    "import scipy as sp\n",
    "from sklearn import datasets, svm, model_selection\n",
    "#from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a) Laden der Daten und Beschreibung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Optical Recognition of Handwritten Digits Data Set\\n===================================================\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 5620\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttp://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\nReferences\\n----------\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.DESCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Merkmalsvektoren (hier Bilder) sind die Zeilen der Designmatrix digits.data. Zusammenstellung einer Zufallsauswahl von 10 Bildern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAABTCAYAAACGep5WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIvx/5wUvtUM0YjAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe7ac3bfb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "%matplotlib inline\n",
    "fig = mp.pyplot.figure()\n",
    "indexes = random.sample(range(0, len(digits.target)), 10)\n",
    "images = []\n",
    "for i, index in zip(range(1, 11), indexes):\n",
    "    mp.pyplot.subplot(1, 10, i)\n",
    "    mp.pyplot.imshow(digits.images[index], cmap=mp.pyplot.cm.gray_r, interpolation='nearest')\n",
    "    images.append((digits.target[index],digits.data[index])) #(label, image)\n",
    "\n",
    "mp.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anzahl Bilder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimension der Bilder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8, 8), (64,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.images[0].shape, digits.data[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teilen Sie den Datensatz zufällig in einen nichtüberlappenden Trainings- und Testdatensatz auf, so dass ein Viertel der Daten zu Testdaten werden. Dies geschieht am Einfachsten mit der Funktion sklearn.model_selection.train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((450, 64), (450,), (1347, 64), (1347,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data, test_data, training_label, test_label = model_selection.train_test_split(digits.data, digits.target, test_size=0.25)\n",
    "test_data.shape, test_label.shape, training_data.shape, training_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainieren Sie einen Supportvektor-Klassifikator (Standard in Scikit Learn ist eine 1-Norm Soft Margin SVM, bei Mehrklassenproblemen wird automatisch ein Satz von one-vs.-one-Klassifikatoren erstellt) mit einem RBF-Kern mit γ = 0.015 und einem Parameter C = 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.015, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(gamma=0.015, C=1.0)\n",
    "clf.fit(training_data, training_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bestimmen Sie den Anteil korrekt klassifizierter Beispiele (Korrektklassifikationsrate, Treffergenauigkeit, engl. Accuracy) im Trainings- und Testdatensatz mithilfe der Funktion SVC.score(). Underfitting liegt vor, wenn Ihr Klassifikator auf den Trainingsdatensatz eine Treffergenauigkeit von deutlich unter 100% erzielt, bei Overfitting liegt die Treffergenauigkeit auf dem Testdatensatz deutlich unter der auf dem Trainingsdatensatz. Welcher Fall liegt hier vor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.366666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected = test_label\n",
    "predicted = clf.predict(test_data)\n",
    "\n",
    "print(clf.score(test_data, test_label))\n",
    "clf.score(training_data, training_label)\n",
    "#expected, predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es handelt sich hierbei um Overfitting. 1.0 > 0.33"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probieren Sie alternativ die SVM-Parameter γ = 0.001 und C = 100 und vergleichen Sie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.991111111111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(gamma=0.001, C=100)\n",
    "clf.fit(training_data, training_label)\n",
    "\n",
    "print(clf.score(test_data, test_label))\n",
    "clf.score(training_data, training_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wiederholen\n",
    "Sie das Experiment für einen anderen Zufallssplit in Trainings- und Testdatensatz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.534269662921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_training_data, r_test_data, r_training_label, r_test_label = model_selection.train_test_split(digits.data, digits.target, test_size=0.99)\n",
    "\n",
    "clf = svm.SVC(gamma=0.001, C=100)\n",
    "clf.fit(r_training_data, r_training_label)\n",
    "\n",
    "print(clf.score(r_test_data, r_test_label))\n",
    "clf.score(r_training_data, r_training_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie stark hängt Ihr Ergebnis von der zufälligen Teilung in Trainings- und Testdatensatz ab?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Es hängt sehr wenig davon ab, da schon wenige Trainingsdaten für ein gutes Ergebnis reichen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Kreuzvalidierung und Modellselektion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Bei der Methode der Kreuzvalidierung wird der zufällige Split in Trainings- und Testdatensatz aus Aufgabe 1 mehrere Male wiederholt und der Durchschnitt über mehrere Splits berechnet, um eine genauere Schätzung der wirklichen Treffergenauigkeit zu erhalten. Scikit Learn stellt dafür bereits eine vordefinierte Methode zur Verfügung: sklearn.model_selection.ShuffleSplit(). Die Methode verwendet die Iteratorsyntax von Python, Beispiele zur Verwendung finden Sie in der Dokumentation dieser Methode. ShuffleSplit() erzeugt einen Satz von permutierten Indizes von Trainings- und Testdaten. Erzeugen Sie zunächst 3 Sätze und trainieren Sie für jeden Satz eine SVM mit γ = 0.001 und C = 1 und geben Sie jeweils die Treffergenauigkeit für Trainings- und Testdatensatz aus. Die Ergebnisse sollten ähnlich wie in Aufgabe 1b aussehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  0.995555555556\n",
      "Training  0.999257609503\n",
      "Test  0.995555555556\n",
      "Training  0.998515219005\n",
      "Test  0.993333333333\n",
      "Training  0.999257609503\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.99481481481481471, 0.99901014600346449)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_number = 3\n",
    "rs = model_selection.ShuffleSplit(n_splits=split_number, test_size=.25, random_state=0)\n",
    "\n",
    "training_mean = 0\n",
    "test_mean = 0\n",
    "\n",
    "for training_indexes, test_indexes in rs.split(digits.data):\n",
    "    t_test_data = []\n",
    "    t_test_label = []\n",
    "    t_training_data = []\n",
    "    t_training_label = []\n",
    "    for test_index in test_indexes:\n",
    "        t_test_data.append(digits.data[test_index])\n",
    "        t_test_label.append(digits.target[test_index])\n",
    "        \n",
    "    for training_index in training_indexes:\n",
    "        t_training_data.append(digits.data[training_index])\n",
    "        t_training_label.append(digits.target[training_index])\n",
    "        \n",
    "    clf = svm.SVC(gamma=0.001, C=1.0)\n",
    "    clf.fit(t_training_data, t_training_label)\n",
    "    test_score = clf.score(t_test_data, t_test_label)\n",
    "    training_score = clf.score(t_training_data, t_training_label)\n",
    "    \n",
    "    test_mean += test_score\n",
    "    training_mean += training_score\n",
    "    print(\"Test \", test_score)\n",
    "    print(\"Training \", training_score)\n",
    "    \n",
    "test_mean/split_number, training_mean/split_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Statt wie in 2a von Hand vorzugehen gibt es in Scikit Learn die bereits vordefinierte\n",
    "Methode sklearn.model_selection.cross_val_score(). Wiederholen Sie Ihr Experiment\n",
    "aus Aufgabe 2a mit 10 Zufallssplits und geben Sie jeweils die Treffergenauigkeit auf dem\n",
    "Testdatensatz aus. Berechnen Sie die mittlere Treffergenauigkeit (die Kreuzvalidierungs-\n",
    "genauigkeit) und die Standardabweichung des Mittelwerts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  [ 0.98039216  0.98        0.97278912]\n",
      "Training  [ 0.98893805  0.99109131  0.99103139]\n",
      "Test  [ 0.96753247  0.97986577  0.96598639]\n",
      "Training  [ 0.98675497  0.99111111  0.97972973]\n",
      "Test  [ 0.98013245  0.97350993  0.97972973]\n",
      "Training  [ 0.99115044  0.99109131  0.98430493]\n",
      "Test  [ 0.97368421  0.98666667  0.9527027 ]\n",
      "Training  [ 0.99115044  0.984375    0.99105145]\n",
      "Test  [ 0.96078431  0.94        0.96598639]\n",
      "Training  [ 0.98451327  0.98886414  0.97982063]\n",
      "Test  [ 0.98039216  0.97333333  0.97959184]\n",
      "Training  [ 0.99113082  0.99109131  0.97986577]\n",
      "Test  [ 0.97402597  0.94666667  0.97260274]\n",
      "Training  [ 0.99337748  0.98666667  0.99099099]\n",
      "Test  [ 0.99346405  0.93288591  0.95945946]\n",
      "Training  [ 0.98893805  0.98444444  0.97752809]\n",
      "Test  [ 0.98039216  0.96666667  0.97278912]\n",
      "Training  [ 0.98230088  0.98886414  0.99327354]\n",
      "Test  [ 0.97368421  0.98        0.95945946]\n",
      "Training  [ 0.99113082  0.9844098   0.98657718]\n"
     ]
    }
   ],
   "source": [
    "split_number = 10\n",
    "rs = model_selection.ShuffleSplit(n_splits=split_number, test_size=.25, random_state=0)\n",
    "\n",
    "training_mean = 0\n",
    "test_mean = 0\n",
    "\n",
    "for training_indexes, test_indexes in rs.split(digits.data):\n",
    "    t_test_data = []\n",
    "    t_test_label = []\n",
    "    t_training_data = []\n",
    "    t_training_label = []\n",
    "    for test_index in test_indexes:\n",
    "        t_test_data.append(digits.data[test_index])\n",
    "        t_test_label.append(digits.target[test_index])\n",
    "        \n",
    "    for training_index in training_indexes:\n",
    "        t_training_data.append(digits.data[training_index])\n",
    "        t_training_label.append(digits.target[training_index])\n",
    "        \n",
    "    clf = svm.SVC(gamma=0.001, C=1.0)\n",
    "    training_score = model_selection.cross_val_score(clf, t_training_data, t_training_label)\n",
    "    test_score = model_selection.cross_val_score(clf, t_test_data, t_test_label)\n",
    "    #clf.fit(t_training_data, t_training_label)\n",
    "    #test_score = clf.score(t_test_data, t_test_label)\n",
    "    #training_score = clf.score(t_training_data, t_training_label)\n",
    "    \n",
    "    #test_mean += test_score\n",
    "    #training_mean += training_score\n",
    "    print(\"Test \", test_score)\n",
    "    print(\"Training \", training_score)\n",
    "    \n",
    "#test_mean/split_number, training_mean/split_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Standardabweichung des Mittelwerts ist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mithilfe der Kreuzvalidierungsgenauigkeit können die optimalen γ- und C-Parameter der SVM automatisch gefunden werden. Dieser Vorgang heißt Modellselektion. Man führt zu diesem Zweck eine Gittersuche durch: zunächst wird ein Satz von Werten für γ und C festgelegt. Für alle Wertepaare wird die Kreuzvalidierungsgenauigkeit bestimmt und dann die Parameter gewählt, die die höchste Treffergenauigkeit erzielen. Finden Sie auf diese Weise für C = 10 den besten Gammawert aus einem Satz von 10 logarithmisch skalierten Gammawerten, erzeugt mit\n",
    "\n",
    "    gammas = np . logspace ( -7 , -1 , 10)\n",
    "\n",
    "Verwenden Sie dazu eine Trainings- und Testdatensatzgröße von 500 und 5 Splits (s. Dokumentation von ShuffleSplit) und speichern Sie die Treffergenauigkeit auf dem Trainingsund Testdatensatz für jeden Gammawert und Split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotten Sie die Treffergenauigkeitskurve für jeden Split mit dem Gammawert als Abszisse in einem gemeinsamen Diagramm, jeweils für die Trainings- und die Testdaten. Diese Kurven werden Validierungskurven genannt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für welche Gammawerte erhalten Sie Underfitting, für welche Overfitting? Wo liegt der optimale Gammawert?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Gittersuche lässt sich ebenfalls automatisieren mit sklearn.model_selection. GridSearchCV(). Wir erzeugen dazu ein Gitter aus Wertepaaren für γ und C mit dem Dictionary\n",
    "\n",
    "    svc_params = {\n",
    "        ’C ’: np . logspace ( -1 , 2 , 4) ,\n",
    "        ’ gamma ’: np . logspace ( -4 , 0 , 5) ,\n",
    "    }\n",
    "\n",
    "Dieses Gitter kann direkt an GridSearchCV() als Argument param_grid übergeben werden. Da diese Prozedur sehr zeitaufwendig ist, verkleinern wie den Datensatz auf die ersten 500 Beispiele. Führen Sie für diesen verkleinerten Datensatz eine Gittersuche mithilfe von GridSearchCV() und jeweils 3 Splits (Parameter cv) durch. Den besten Parametersatz erhalten Sie mit GridSearchCV().best_params_, die höchste Treffergenauigkeit mit GridSearchCV().best_score_. Ausführliche Informationen zu jedem Parameterwertepaar stehen in dem Dictionary GridSearchCV().cv_results_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nach der Gittersuche führt GridSearchCV() noch ein Training auf dem gesamten Datensatz mit den besten Parametern durch, so dass die resultierende Maschine sofort eingesetzt werden kann. Testen Sie diese Maschine auf den übriggebliebenen Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konfiguration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "Software versions": [
        {
         "module": "Python",
         "version": "3.5.2 64bit [GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]"
        },
        {
         "module": "IPython",
         "version": "5.1.0"
        },
        {
         "module": "OS",
         "version": "Linux 4.2.0 27 generic x86_64 with debian jessie sid"
        },
        {
         "module": "numpy",
         "version": "1.11.1"
        },
        {
         "module": "pandas",
         "version": "0.18.1"
        },
        {
         "module": "matplotlib",
         "version": "1.5.3"
        },
        {
         "module": "skimage",
         "version": "0.12.3"
        },
        {
         "module": "sklearn",
         "version": "0.18.1"
        }
       ]
      },
      "text/html": [
       "<table><tr><th>Software</th><th>Version</th></tr><tr><td>Python</td><td>3.5.2 64bit [GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]</td></tr><tr><td>IPython</td><td>5.1.0</td></tr><tr><td>OS</td><td>Linux 4.2.0 27 generic x86_64 with debian jessie sid</td></tr><tr><td>numpy</td><td>1.11.1</td></tr><tr><td>pandas</td><td>0.18.1</td></tr><tr><td>matplotlib</td><td>1.5.3</td></tr><tr><td>skimage</td><td>0.12.3</td></tr><tr><td>sklearn</td><td>0.18.1</td></tr><tr><td colspan='2'>Fri Dec 30 22:24:32 2016 CET</td></tr></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{|l|l|}\\hline\n",
       "{\\bf Software} & {\\bf Version} \\\\ \\hline\\hline\n",
       "Python & 3.5.2 64bit [GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] \\\\ \\hline\n",
       "IPython & 5.1.0 \\\\ \\hline\n",
       "OS & Linux 4.2.0 27 generic x86\\_64 with debian jessie sid \\\\ \\hline\n",
       "numpy & 1.11.1 \\\\ \\hline\n",
       "pandas & 0.18.1 \\\\ \\hline\n",
       "matplotlib & 1.5.3 \\\\ \\hline\n",
       "skimage & 0.12.3 \\\\ \\hline\n",
       "sklearn & 0.18.1 \\\\ \\hline\n",
       "\\hline \\multicolumn{2}{|l|}{Fri Dec 30 22:24:32 2016 CET} \\\\ \\hline\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "Software versions\n",
       "Python 3.5.2 64bit [GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n",
       "IPython 5.1.0\n",
       "OS Linux 4.2.0 27 generic x86_64 with debian jessie sid\n",
       "numpy 1.11.1\n",
       "pandas 0.18.1\n",
       "matplotlib 1.5.3\n",
       "skimage 0.12.3\n",
       "sklearn 0.18.1\n",
       "Fri Dec 30 22:24:32 2016 CET"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext version_information\n",
    "%version_information numpy, pandas, matplotlib, skimage, sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
